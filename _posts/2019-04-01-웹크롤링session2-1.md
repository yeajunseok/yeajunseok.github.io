---
title: "웹 크롤링_1"
header:
 overlay_image: /assets/images/overlayimage.jpg
categories:
  - 웹 크롤링
tags:
  - urlretrieve()
  - urlopen()
toc: true
toc_label: "My Table of Contents"
toc_sticky: true
---
웹 크롤링과 웹 스크래핑의 차이  

# urlretrieve
```python
import urllib.request

imgUrl = "http://imgnews.naver.net/image/002/2017/03/13/0002026985_001_20170313153101670.jpg"
savePath1 = "c:/Users/yeajunseok/Documents/Atom/WebCrawling_python/session2/test1.jpg"

urllib.request.urlretrieve(imgUrl, savePath1)

print("다운로드 완료!")
```  

**urlretrieve**  
 내가 정한 경로에 이미지를 **다이렉트로 다운받는다.**  
 '파싱'이 필요없는 데이터(이미지, 엑셀, 여러문서 한번에 다운받을때)는 urlretrieve를 사용한다.  

# urlopen
```python
import urllib.request

imgUrl = "http://imgnews.naver.net/image/002/2017/03/13/0002026985_001_20170313153101670.jpg"
----------------------------------
# 방법 <1>, close를 해줘야 한다.
f = urllib.request.urlopen(imgUrl).read() #우리의 하드디스크에 저장되기 전에 변수에(메모리)저장 시킨다.

savefile1 = open(savePath1, 'wb') #w : write, r : read, a : add / b: 바이너리로
savefile1.write(f)
savefile1.close()
----------------------------------
# 방법 <2>, 위 방법보다 with문을 사용하는것이 좋다. 왜냐하면 with문은 자동으로 close를 해주기 때문이다.
f2 = urllib.request.urlopen(htmlUrl).read()

with open(savePath2, 'wb') as savefile2:
    savefile2.write(f2)

print("다운로드 완료!")
```

**urlopen**  
 변수(메모리)에 먼저 할당하고 -> 파싱 -> 저장  
 중간에서 필요로하는 것을 분석할때 urlopen을 사용하자.
